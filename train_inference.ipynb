{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一部分：使用指令数据对基底模型进行有监督微调\n",
    "在本作业的第一部分，我们将使用Qwen2.5-0.5B基底模型以及alpaca指令数据集，体验如何对LLM做指令微调的训练。\n",
    "\n",
    "> 关于Transformer的基本使用教程，可以参考官方推出的[LLM Course](https://huggingface.co/learn/llm-course/chapter2/3)。本次作业要求同学们手写训练代码，不能使用里面提供的Trainer API，关于如何使用PyTorch训练模型，可以参照[这个教程](https://huggingface.co/docs/transformers/v4.49.0/en/training#train-in-native-pytorch)。\n",
    "\n",
    "> 对于使用Kaggle进行作业的同学，这里有一份[Kaggle基础使用](https://www.kaggle.com/code/cnlnpjhsy/kaggle-transformers)的简单教学供参考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果缺失必要的库，可以使用下面的命令安装\n",
    "!pip install -U torch transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型、tokenizer与数据集\n",
    "本次作业，我们使用通义千问的Qwen2.5-0.5B预训练模型进行微调。对于在本地部署的同学，请事先将模型文件下载到本地；对于在kaggle上进行作业的同学，可以依照kaggle上的教程，将`MODEL_PATH`与`DATASET_PATH`修改为Input中的路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")\n",
      "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'}\n",
      "{'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).'}\n",
      "{'instruction': 'Describe the structure of an atom.', 'input': '', 'output': \"An atom is the basic building block of all matter and is made up of three types of particles: protons, neutrons, and electrons. The structure of an atom can be described as a nucleus at the center surrounded by a cloud of electrons.\\n\\nThe nucleus of an atom is made up of protons and neutrons. Protons are positively charged particles and neutrons are neutral particles with no charge. Both of these particles are located in the nucleus of the atom, which is at the center of the atom and contains most of the atom's mass.\\n\\nSurrounding the nucleus of the atom is a cloud of electrons. Electrons are negatively charged particles that are in constant motion around the nucleus. The electron cloud is divided into shells or orbitals, and each shell can hold a certain number of electrons. The number of electrons in the outermost shell, called the valence shell, determines the chemical properties of the atom. \\n\\nIn a neutral atom, the number of protons in the nucleus is equal to the number of electrons in the electron cloud, so the positive and negative charges balance out and the atom has no overall charge. The number of protons, also called the atomic number, determines what element the atom is.\"}\n",
      "{'instruction': 'How can we reduce air pollution?', 'input': '', 'output': 'There are several ways to reduce air pollution, including:\\n\\n1. Reduce energy consumption: By conserving energy, we reduce the amount of pollution emitted from power plants. Some ways to achieve this include: using energy-efficient appliances and lighting, insulating homes, and shutting off lights and electronics when not in use.\\n\\n2. Use public transportation or carpool: Cars and trucks are major sources of pollution. By using public transportation, carpooling or biking, you can reduce the number of cars on the road, which in turn reduces emissions.\\n\\n3. Be responsible with waste: When waste is burned or decomposed, they can release harmful gases into the air. Dispose of hazardous waste correctly and recycle materials like plastics, paper, and glass when possible.\\n\\n4. Support clean energy sources: Renewable energy sources like solar and wind power generate little or no pollution. Support clean energy companies and projects, and consider installing renewable energy systems in your home.\\n\\n5. Drive efficiently: If you need to drive, make sure your vehicle is well maintained and drive efficiently by avoiding rapid acceleration and braking, and reducing idling.\\n\\n6. Be mindful of product choices: Some products and practices release more pollution than others. Choose products with eco-friendly packaging and try to minimize your use of aerosol sprays, which can release harmful chemicals into the air.'}\n",
      "{'instruction': 'Pretend you are a project manager of a construction company. Describe a time when you had to make a difficult decision.', 'input': '', 'output': 'I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.'}\n",
      "{'instruction': 'Write a concise summary of the following:\\n\"Commodore 64 (commonly known as the C64 or CBM 64) was manufactured by Commodore Business Machine (CBM) in August 1982 with a starting price of $595. It was an 8-bit home computer with remarkable market success. Between 1983-1986, C64 sales amounted to about 17 million units sold, making them the best-selling single personal computer model of all time in 1983-1986. \\n\\nAdditionally, the Commodore 64 dominated the market with between 30% and 40% share and 2 million units sold per year, outselling the IBM PC clones, Apple Computers, and Atari computers. Adding to their success, Sam Tramiel (former Atari president), during an interview in 1989, said they were building 400,000 C64s a month for a couple of years. \"', 'input': '', 'output': 'The Commodore 64 was a highly successful 8-bit home computer manufactured by Commodore Business Machine (CBM) in 1982, with sales amounting to approximately 17 million units sold between 1983-1986. It dominated the market with between 30% and 40% share and outsold its competitors, including IBM PC clones, Apple Computers, and Atari computers. At its peak, CBM was building 400,000 C64s a month for a couple of years.'}\n",
      "{'instruction': 'Explain why the following fraction is equivalent to 1/4', 'input': '4/16', 'output': 'The fraction 4/16 is equivalent to 1/4 because both fractions represent the same value. A fraction can be simplified by dividing both the numerator and the denominator by a common factor. In this case, 4 is a common factor of both the numerator and the denominator of 4/16. When we divide both by 4, we get 4/4 = 1 and 16/4 = 4, so the simplified fraction is 1/4. Alternatively, we can think of this in terms of multiplication. For example, if we multiply the numerator and denominator of the fraction 1/4 by 4, we get (1x4)/(4x4), or 4/16. Since both fractions can be derived from the other through multiplication or division by the same number, they represent the same value and are equivalent.'}\n",
      "{'instruction': 'Write a short story in third person narration about a protagonist who has to make an important career decision.', 'input': '', 'output': \"Sophie sat at her desk, staring blankly at the computer screen. Her mind was racing as she weighed the options in front of her. She had been offered a promotion to a senior management position within her company, but it meant moving across the country and leaving her friends and family behind. At the same time, her dream job at a rival company had finally opened up, and she had been invited for an interview. \\n\\nThe thought of leaving her comfortable life behind, to take a chance on something new and uncertain, made Sophie feel anxious, but also excited. She had always been one to take risks, and it had paid off in the past. But now, with such a big decision to make, Sophie couldn't help but feel overwhelmed.\\n\\nAfter much deliberation, Sophie made her choice. She packed her bags, said goodbye to her loved ones, and moved across the country for the new job. It was a difficult first few months, adjusting to a new city and a new company culture. But as time went by, Sophie realized that she had made the best decision for her career. The job was challenging, but also rewarding, and she was surrounded by passionate, driven colleagues who inspired her to grow and develop.\\n\\nIn the end, Sophie's bold move paid off. She was thriving in her new role, and had made new friends and connections in her new city. Looking back, Sophie was grateful for the opportunity to take a risk and make a change, and was confident that she had made the right decision for her career.\"}\n",
      "{'instruction': 'Evaluate this sentence for spelling and grammar mistakes', 'input': 'He finnished his meal and left the resturant', 'output': 'There are two spelling errors in the sentence. The corrected sentence should be: \"He finished his meal and left the restaurant.\"'}\n",
      "{'instruction': 'How did Julius Caesar die?', 'input': '', 'output': \"Julius Caesar, the Roman Military general, and statesman was assassinated on March 15, 44 BC. He was stabbed to death at a meeting of the Senate in the Theatre of Pompey by a group of senators who called themselves the Liberatores. Led by Gaius Cassius Longinus, and Marcus Junius Brutus, they believed that Caesar's dictatorship was subverting the Roman Republic and sought to restore the traditional republican government. The exact number of assailants is not known, but it is believed that a group of as many as 60 conspirators participated in the assassination, and each of them took turns in stabbing Caesar. The day of his death is still known as the Ides of March.\"}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"./Qwen2.5-0.5B\"  # 请确保服务器当前目录下有 Qwen2.5-0.5B 文件夹\n",
    "DATASET_PATH = \"./alpaca-cleaned/alpaca_data_cleaned.json\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "print(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "dataset = datasets.Dataset.from_json(DATASET_PATH)\n",
    "for sample in dataset.select(range(10)):    # 查看前10个样本。思考应该怎么将样本组织成单条完整文本？\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen为基底模型也提供了对话模板（chat template），对话模板中含有一些特殊的token，可以帮助我们区分说话人的轮次（思考一下为什么要区分？）。我们可以直接以下述“轮次对话”的方式，构造一个样例文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nThis is a question.<|im_end|>\\n<|im_start|>assistant\\nI'm the answer!<|im_end|>\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template([\n",
    "    {\"role\": \"user\", \"content\": \"This is a question.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm the answer!\"}\n",
    "], tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到每一轮次的对话都以`<|im_end|>`这个token结束。但是基底模型是没有在对话上经过优化的，它并不认得这个终止符。因此我们需要修改tokenizer的终止符，使其知道什么token代表一个对话轮次的结束。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token)  # 原来的终止符\n",
    "tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.eos_token_id = tokenizer.eos_token_id  # 也要修改模型的终止符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了与训练后的模型做对比，我们先使用模型自带的generate方法测试一下这个基底模型会生成什么样的文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai Jiao Tong University (JTU) is a public university in Shanghai, China. It was founded in 1905 and is one of the oldest universities in China. The university has a rich history and is known for its academic excellence, research, and teaching. It offers a wide range of undergraduate and graduate programs in various fields, including engineering, business, and social sciences. The university also has a strong international presence and is home to several prestigious research centers and institutes. Overall, Shanghai Jiao Tong University is a highly regarded institution that has made significant contributions to the development of China's education and research.\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "-transitional\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Give me a brief introduction to Shanghai Jiao Tong University.\"},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "with torch.no_grad():\n",
    "    lm_inputs_src = tokenizer([text], add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "    generate_ids = model.generate(**lm_inputs_src, max_new_tokens=150, do_sample=False)\n",
    "pred_str = tokenizer.decode(generate_ids[0][lm_inputs_src.input_ids.size(1):], skip_special_tokens=True)\n",
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据集\n",
    "原始的alpaca数据集是纯文本形式，而非模型能够接受的token。我们需要先将这些文本tokenize，再传给模型。\n",
    "\n",
    "在指令微调阶段，我们常常希望模型只在模型要生成回答的部分上做优化，而不在问题文本上做训练，这需要我们特别设计传入的标签。请完成下述的`tokenize_function`函数，将数据集的指令样本tokenize，并传回输入模型的`input_ids`以及用于<b>仅在output部分计算损失</b>的标签`labels`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def tokenize_function(sample):\n",
    "    input_ids = None\n",
    "    labels = None\n",
    "    instruction = sample[\"instruction\"]\n",
    "    input_text = sample.get(\"input\", \"\")\n",
    "    output_text = sample[\"output\"]\n",
    "\n",
    "    if input_text:\n",
    "        user_content = f\"{instruction}\\n\\n{input_text}\"\n",
    "    else:\n",
    "        user_content = instruction\n",
    "\n",
    "    messages_full = [\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"assistant\", \"content\": output_text},\n",
    "    ]\n",
    "    full_text = tokenizer.apply_chat_template(messages_full, tokenize=False)\n",
    "\n",
    "    messages_prompt = [{\"role\": \"user\", \"content\": user_content}]\n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        messages_prompt, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    full_ids = tokenizer(full_text, add_special_tokens=False)[\"input_ids\"]\n",
    "    prompt_ids = tokenizer(prompt_text, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "    labels = copy.copy(full_ids)\n",
    "    ignore_len = len(prompt_ids)\n",
    "    if ignore_len > 0:\n",
    "        labels[:ignore_len] = [-100] * ignore_len\n",
    "\n",
    "    return {\"input_ids\": full_ids, \"labels\": labels}\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function, remove_columns=dataset.column_names\n",
    ").filter(\n",
    "    lambda x: len(x[\"input_ids\"]) <= 512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个DataLoader，用于从中获取模型能够处理的tokenized输入。  \n",
    "> <b>【附加1】（3分）</b>通过从dataloader中成批取出数据，可以提升计算效率。你能够设计`collate_fn`，使之能以`batch_size > 1`的方式获取数据吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = None\n",
    "    attention_mask = None\n",
    "    labels = None\n",
    "    input_ids = None\n",
    "    attention_mask = None\n",
    "    labels = None\n",
    "\n",
    "    input_ids_list = [sample[\"input_ids\"] for sample in batch]\n",
    "    labels_list = [sample[\"labels\"] for sample in batch]\n",
    "\n",
    "    max_len = max(len(ids) for ids in input_ids_list)\n",
    "\n",
    "    padded_input_ids = []\n",
    "    padded_labels = []\n",
    "    attention_masks = []\n",
    "\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "\n",
    "    for ids, lbs in zip(input_ids_list, labels_list):\n",
    "        pad_len = max_len - len(ids)\n",
    "        \n",
    "        padded_ids = ids + [pad_id] * pad_len\n",
    "        padded_input_ids.append(padded_ids)\n",
    "\n",
    "        padded_lbs = lbs + [-100] * pad_len\n",
    "        padded_labels.append(padded_lbs)\n",
    "\n",
    "        attn_mask = [1] * len(ids) + [0] * pad_len\n",
    "        attention_masks.append(attn_mask)\n",
    "\n",
    "    input_ids = torch.tensor(padded_input_ids, dtype=torch.long)\n",
    "    attention_mask = torch.tensor(attention_masks, dtype=torch.long)\n",
    "    labels = torch.tensor(padded_labels, dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "train_dataloader = DataLoader(tokenized_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)  # Optimized for H200 (Batch 128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "准备好tokenized后的数据后，就可以对模型进行训练了。请手动编写用于训练的循环，计算损失并反传。\n",
    "\n",
    "在向model传入labels时，Transformer模型内部会自动计算损失；但为了让同学们理解损失的内部计算机制，我们要求**不向模型forward中传入labels，而是手动将模型的最终输出logits与labels相比对，并计算损失。**  \n",
    "> <b>【附加1】</b>从dataloader中成批获取数据后，要将整个batch一次性输入到模型中（并非是使用循环逐个处理批次输入），获取所有样例的loss，并正确计算损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca369c25b0547f095f87973bce035fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd12eb8298c449fbab096c567d05af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/12766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100\t| Loss: 1.390625\n",
      "Step 200\t| Loss: 1.5\n",
      "Step 300\t| Loss: 1.1640625\n",
      "Step 400\t| Loss: 1.6171875\n",
      "Step 500\t| Loss: 1.5078125\n",
      "Step 600\t| Loss: 1.59375\n",
      "Step 700\t| Loss: 1.625\n",
      "Step 800\t| Loss: 1.3046875\n",
      "Step 900\t| Loss: 1.7265625\n",
      "Step 1000\t| Loss: 1.703125\n",
      "Step 1100\t| Loss: 1.8203125\n",
      "Step 1200\t| Loss: 1.40625\n",
      "Step 1300\t| Loss: 1.703125\n",
      "Step 1400\t| Loss: 1.3984375\n",
      "Step 1500\t| Loss: 1.3359375\n",
      "Step 1600\t| Loss: 0.98046875\n",
      "Step 1700\t| Loss: 1.7578125\n",
      "Step 1800\t| Loss: 1.4765625\n",
      "Step 1900\t| Loss: 1.5859375\n",
      "Step 2000\t| Loss: 1.8359375\n",
      "Step 2100\t| Loss: 1.2734375\n",
      "Step 2200\t| Loss: 1.5703125\n",
      "Step 2300\t| Loss: 1.6640625\n",
      "Step 2400\t| Loss: 1.2109375\n",
      "Step 2500\t| Loss: 1.1484375\n",
      "Step 2600\t| Loss: 1.9765625\n",
      "Step 2700\t| Loss: 1.5\n",
      "Step 2800\t| Loss: 1.046875\n",
      "Step 2900\t| Loss: 1.625\n",
      "Step 3000\t| Loss: 2.046875\n",
      "Step 3100\t| Loss: 0.7890625\n",
      "Step 3200\t| Loss: 1.1953125\n",
      "Step 3300\t| Loss: 1.5703125\n",
      "Step 3400\t| Loss: 0.94140625\n",
      "Step 3500\t| Loss: 1.65625\n",
      "Step 3600\t| Loss: 1.375\n",
      "Step 3700\t| Loss: 1.578125\n",
      "Step 3800\t| Loss: 1.390625\n",
      "Step 3900\t| Loss: 0.75\n",
      "Step 4000\t| Loss: 0.99609375\n",
      "Step 4100\t| Loss: 1.4921875\n",
      "Step 4200\t| Loss: 1.4296875\n",
      "Step 4300\t| Loss: 1.1171875\n",
      "Step 4400\t| Loss: 1.8671875\n",
      "Step 4500\t| Loss: 1.3203125\n",
      "Step 4600\t| Loss: 1.3828125\n",
      "Step 4700\t| Loss: 0.984375\n",
      "Step 4800\t| Loss: 1.0546875\n",
      "Step 4900\t| Loss: 1.625\n",
      "Step 5000\t| Loss: 0.53515625\n",
      "Step 5100\t| Loss: 1.1328125\n",
      "Step 5200\t| Loss: 1.0625\n",
      "Step 5300\t| Loss: 1.140625\n",
      "Step 5400\t| Loss: 2.109375\n",
      "Step 5500\t| Loss: 1.734375\n",
      "Step 5600\t| Loss: 1.1875\n",
      "Step 5700\t| Loss: 1.3984375\n",
      "Step 5800\t| Loss: 1.0078125\n",
      "Step 5900\t| Loss: 1.6328125\n",
      "Step 6000\t| Loss: 1.46875\n",
      "Step 6100\t| Loss: 1.5546875\n",
      "Step 6200\t| Loss: 1.390625\n",
      "Step 6300\t| Loss: 0.99609375\n",
      "Step 6400\t| Loss: 1.25\n",
      "Step 6500\t| Loss: 1.6875\n",
      "Step 6600\t| Loss: 1.421875\n",
      "Step 6700\t| Loss: 1.1640625\n",
      "Step 6800\t| Loss: 1.2421875\n",
      "Step 6900\t| Loss: 1.328125\n",
      "Step 7000\t| Loss: 1.015625\n",
      "Step 7100\t| Loss: 1.3046875\n",
      "Step 7200\t| Loss: 0.91796875\n",
      "Step 7300\t| Loss: 1.5\n",
      "Step 7400\t| Loss: 1.34375\n",
      "Step 7500\t| Loss: 1.78125\n",
      "Step 7600\t| Loss: 1.6171875\n",
      "Step 7700\t| Loss: 2.515625\n",
      "Step 7800\t| Loss: 1.2109375\n",
      "Step 7900\t| Loss: 1.1953125\n",
      "Step 8000\t| Loss: 1.671875\n",
      "Step 8100\t| Loss: 1.8046875\n",
      "Step 8200\t| Loss: 1.515625\n",
      "Step 8300\t| Loss: 1.234375\n",
      "Step 8400\t| Loss: 1.3984375\n",
      "Step 8500\t| Loss: 1.0390625\n",
      "Step 8600\t| Loss: 1.5078125\n",
      "Step 8700\t| Loss: 1.171875\n",
      "Step 8800\t| Loss: 1.25\n",
      "Step 8900\t| Loss: 1.3359375\n",
      "Step 9000\t| Loss: 0.80859375\n",
      "Step 9100\t| Loss: 1.328125\n",
      "Step 9200\t| Loss: 1.1953125\n",
      "Step 9300\t| Loss: 1.3515625\n",
      "Step 9400\t| Loss: 1.625\n",
      "Step 9500\t| Loss: 1.296875\n",
      "Step 9600\t| Loss: 1.34375\n",
      "Step 9700\t| Loss: 2.0625\n",
      "Step 9800\t| Loss: 1.71875\n",
      "Step 9900\t| Loss: 1.4453125\n",
      "Step 10000\t| Loss: 0.90625\n",
      "Step 10100\t| Loss: 1.3515625\n",
      "Step 10200\t| Loss: 1.765625\n",
      "Step 10300\t| Loss: 1.421875\n",
      "Step 10400\t| Loss: 1.109375\n",
      "Step 10500\t| Loss: 1.3046875\n",
      "Step 10600\t| Loss: 1.078125\n",
      "Step 10700\t| Loss: 1.6796875\n",
      "Step 10800\t| Loss: 1.4140625\n",
      "Step 10900\t| Loss: 1.4453125\n",
      "Step 11000\t| Loss: 1.5546875\n",
      "Step 11100\t| Loss: 1.8203125\n",
      "Step 11200\t| Loss: 1.21875\n",
      "Step 11300\t| Loss: 1.6640625\n",
      "Step 11400\t| Loss: 1.703125\n",
      "Step 11500\t| Loss: 1.3671875\n",
      "Step 11600\t| Loss: 1.2109375\n",
      "Step 11700\t| Loss: 1.4375\n",
      "Step 11800\t| Loss: 1.3359375\n",
      "Step 11900\t| Loss: 1.25\n",
      "Step 12000\t| Loss: 1.609375\n",
      "Step 12100\t| Loss: 1.8125\n",
      "Step 12200\t| Loss: 1.25\n",
      "Step 12300\t| Loss: 1.484375\n",
      "Step 12400\t| Loss: 1.4765625\n",
      "Step 12500\t| Loss: 1.3984375\n",
      "Step 12600\t| Loss: 0.84375\n",
      "Step 12700\t| Loss: 1.390625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c578fb93e83a41d784bb8aa313cb2bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/12766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12800\t| Loss: 1.46875\n",
      "Step 12900\t| Loss: 1.2578125\n",
      "Step 13000\t| Loss: 0.86328125\n",
      "Step 13100\t| Loss: 0.96484375\n",
      "Step 13200\t| Loss: 1.5078125\n",
      "Step 13300\t| Loss: 1.4453125\n",
      "Step 13400\t| Loss: 1.2578125\n",
      "Step 13500\t| Loss: 0.96484375\n",
      "Step 13600\t| Loss: 0.90234375\n",
      "Step 13700\t| Loss: 1.0703125\n",
      "Step 13800\t| Loss: 1.2421875\n",
      "Step 13900\t| Loss: 1.09375\n",
      "Step 14000\t| Loss: 0.78515625\n",
      "Step 14100\t| Loss: 0.93359375\n",
      "Step 14200\t| Loss: 1.3203125\n",
      "Step 14300\t| Loss: 0.81640625\n",
      "Step 14400\t| Loss: 1.328125\n",
      "Step 14500\t| Loss: 1.015625\n",
      "Step 14600\t| Loss: 1.0703125\n",
      "Step 14700\t| Loss: 1.1875\n",
      "Step 14800\t| Loss: 1.0234375\n",
      "Step 14900\t| Loss: 0.8515625\n",
      "Step 15000\t| Loss: 1.1953125\n",
      "Step 15100\t| Loss: 1.0078125\n",
      "Step 15200\t| Loss: 0.87890625\n",
      "Step 15300\t| Loss: 1.1796875\n",
      "Step 15400\t| Loss: 1.1953125\n",
      "Step 15500\t| Loss: 0.90625\n",
      "Step 15600\t| Loss: 0.91796875\n",
      "Step 15700\t| Loss: 0.53515625\n",
      "Step 15800\t| Loss: 0.99609375\n",
      "Step 15900\t| Loss: 1.15625\n",
      "Step 16000\t| Loss: 0.6640625\n",
      "Step 16100\t| Loss: 0.9765625\n",
      "Step 16200\t| Loss: 1.25\n",
      "Step 16300\t| Loss: 1.015625\n",
      "Step 16400\t| Loss: 0.546875\n",
      "Step 16500\t| Loss: 1.125\n",
      "Step 16600\t| Loss: 1.0859375\n",
      "Step 16700\t| Loss: 0.98046875\n",
      "Step 16800\t| Loss: 0.96484375\n",
      "Step 16900\t| Loss: 0.8359375\n",
      "Step 17000\t| Loss: 0.89453125\n",
      "Step 17100\t| Loss: 1.15625\n",
      "Step 17200\t| Loss: 1.296875\n",
      "Step 17300\t| Loss: 1.203125\n",
      "Step 17400\t| Loss: 1.5390625\n",
      "Step 17500\t| Loss: 1.15625\n",
      "Step 17600\t| Loss: 1.5703125\n",
      "Step 17700\t| Loss: 1.4609375\n",
      "Step 17800\t| Loss: 1.46875\n",
      "Step 17900\t| Loss: 0.63671875\n",
      "Step 18000\t| Loss: 1.3203125\n",
      "Step 18100\t| Loss: 0.9375\n",
      "Step 18200\t| Loss: 1.1015625\n",
      "Step 18300\t| Loss: 1.4921875\n",
      "Step 18400\t| Loss: 1.2890625\n",
      "Step 18500\t| Loss: 0.4453125\n",
      "Step 18600\t| Loss: 1.359375\n",
      "Step 18700\t| Loss: 0.98046875\n",
      "Step 18800\t| Loss: 1.09375\n",
      "Step 18900\t| Loss: 1.296875\n",
      "Step 19000\t| Loss: 0.79296875\n",
      "Step 19100\t| Loss: 0.79296875\n",
      "Step 19200\t| Loss: 1.2265625\n",
      "Step 19300\t| Loss: 1.3203125\n",
      "Step 19400\t| Loss: 0.78125\n",
      "Step 19500\t| Loss: 1.1875\n",
      "Step 19600\t| Loss: 1.296875\n",
      "Step 19700\t| Loss: 1.546875\n",
      "Step 19800\t| Loss: 1.21875\n",
      "Step 19900\t| Loss: 0.8984375\n",
      "Step 20000\t| Loss: 0.9765625\n",
      "Step 20100\t| Loss: 0.80078125\n",
      "Step 20200\t| Loss: 0.859375\n",
      "Step 20300\t| Loss: 0.7890625\n",
      "Step 20400\t| Loss: 1.296875\n",
      "Step 20500\t| Loss: 1.46875\n",
      "Step 20600\t| Loss: 1.2109375\n",
      "Step 20700\t| Loss: 1.140625\n",
      "Step 20800\t| Loss: 1.21875\n",
      "Step 20900\t| Loss: 1.1875\n",
      "Step 21000\t| Loss: 1.15625\n",
      "Step 21100\t| Loss: 0.96875\n",
      "Step 21200\t| Loss: 1.0078125\n",
      "Step 21300\t| Loss: 1.078125\n",
      "Step 21400\t| Loss: 1.375\n",
      "Step 21500\t| Loss: 1.1640625\n",
      "Step 21600\t| Loss: 0.66015625\n",
      "Step 21700\t| Loss: 0.65234375\n",
      "Step 21800\t| Loss: 1.046875\n",
      "Step 21900\t| Loss: 0.875\n",
      "Step 22000\t| Loss: 0.8125\n",
      "Step 22100\t| Loss: 1.1875\n",
      "Step 22200\t| Loss: 0.94921875\n",
      "Step 22300\t| Loss: 1.1953125\n",
      "Step 22400\t| Loss: 0.8359375\n",
      "Step 22500\t| Loss: 1.140625\n",
      "Step 22600\t| Loss: 0.875\n",
      "Step 22700\t| Loss: 0.9296875\n",
      "Step 22800\t| Loss: 0.515625\n",
      "Step 22900\t| Loss: 1.1796875\n",
      "Step 23000\t| Loss: 0.55078125\n",
      "Step 23100\t| Loss: 1.1015625\n",
      "Step 23200\t| Loss: 1.28125\n",
      "Step 23300\t| Loss: 0.9453125\n",
      "Step 23400\t| Loss: 1.09375\n",
      "Step 23500\t| Loss: 1.6015625\n",
      "Step 23600\t| Loss: 1.109375\n",
      "Step 23700\t| Loss: 1.2890625\n",
      "Step 23800\t| Loss: 1.0625\n",
      "Step 23900\t| Loss: 1.1796875\n",
      "Step 24000\t| Loss: 1.0390625\n",
      "Step 24100\t| Loss: 1.46875\n",
      "Step 24200\t| Loss: 0.9453125\n",
      "Step 24300\t| Loss: 1.359375\n",
      "Step 24400\t| Loss: 0.7578125\n",
      "Step 24500\t| Loss: 0.90234375\n",
      "Step 24600\t| Loss: 1.4765625\n",
      "Step 24700\t| Loss: 1.2109375\n",
      "Step 24800\t| Loss: 1.0234375\n",
      "Step 24900\t| Loss: 1.3125\n",
      "Step 25000\t| Loss: 1.1796875\n",
      "Step 25100\t| Loss: 0.69921875\n",
      "Step 25200\t| Loss: 1.4296875\n",
      "Step 25300\t| Loss: 0.6875\n",
      "Step 25400\t| Loss: 0.984375\n",
      "Step 25500\t| Loss: 0.87890625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22c094f56154a6597b755e654cda1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/12766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25600\t| Loss: 0.62890625\n",
      "Step 25700\t| Loss: 1.0078125\n",
      "Step 25800\t| Loss: 0.86328125\n",
      "Step 25900\t| Loss: 0.9765625\n",
      "Step 26000\t| Loss: 1.3671875\n",
      "Step 26100\t| Loss: 0.55859375\n",
      "Step 26200\t| Loss: 1.2109375\n",
      "Step 26300\t| Loss: 1.046875\n",
      "Step 26400\t| Loss: 1.125\n",
      "Step 26500\t| Loss: 0.42578125\n",
      "Step 26600\t| Loss: 1.140625\n",
      "Step 26700\t| Loss: 1.0\n",
      "Step 26800\t| Loss: 0.953125\n",
      "Step 26900\t| Loss: 0.96484375\n",
      "Step 27000\t| Loss: 0.92578125\n",
      "Step 27100\t| Loss: 0.75\n",
      "Step 27200\t| Loss: 0.68359375\n",
      "Step 27300\t| Loss: 1.1796875\n",
      "Step 27400\t| Loss: 1.0\n",
      "Step 27500\t| Loss: 0.98828125\n",
      "Step 27600\t| Loss: 1.1484375\n",
      "Step 27700\t| Loss: 0.50390625\n",
      "Step 27800\t| Loss: 0.98046875\n",
      "Step 27900\t| Loss: 1.09375\n",
      "Step 28000\t| Loss: 1.03125\n",
      "Step 28100\t| Loss: 0.369140625\n",
      "Step 28200\t| Loss: 1.109375\n",
      "Step 28300\t| Loss: 0.7734375\n",
      "Step 28400\t| Loss: 1.0703125\n",
      "Step 28500\t| Loss: 1.3671875\n",
      "Step 28600\t| Loss: 1.1328125\n",
      "Step 28700\t| Loss: 1.328125\n",
      "Step 28800\t| Loss: 0.462890625\n",
      "Step 28900\t| Loss: 0.7734375\n",
      "Step 29000\t| Loss: 1.0390625\n",
      "Step 29100\t| Loss: 0.796875\n",
      "Step 29200\t| Loss: 0.80859375\n",
      "Step 29300\t| Loss: 1.328125\n",
      "Step 29400\t| Loss: 0.7734375\n",
      "Step 29500\t| Loss: 0.76953125\n",
      "Step 29600\t| Loss: 1.21875\n",
      "Step 29700\t| Loss: 1.0078125\n",
      "Step 29800\t| Loss: 0.74609375\n",
      "Step 29900\t| Loss: 1.0546875\n",
      "Step 30000\t| Loss: 1.1015625\n",
      "Step 30100\t| Loss: 1.265625\n",
      "Step 30200\t| Loss: 1.1015625\n",
      "Step 30300\t| Loss: 0.9765625\n",
      "Step 30400\t| Loss: 0.7578125\n",
      "Step 30500\t| Loss: 0.703125\n",
      "Step 30600\t| Loss: 1.1796875\n",
      "Step 30700\t| Loss: 0.94921875\n",
      "Step 30800\t| Loss: 1.125\n",
      "Step 30900\t| Loss: 0.92578125\n",
      "Step 31000\t| Loss: 1.0234375\n",
      "Step 31100\t| Loss: 1.21875\n",
      "Step 31200\t| Loss: 0.4921875\n",
      "Step 31300\t| Loss: 1.46875\n",
      "Step 31400\t| Loss: 0.5703125\n",
      "Step 31500\t| Loss: 1.15625\n",
      "Step 31600\t| Loss: 0.6953125\n",
      "Step 31700\t| Loss: 1.2109375\n",
      "Step 31800\t| Loss: 1.171875\n",
      "Step 31900\t| Loss: 0.5078125\n",
      "Step 32000\t| Loss: 1.1484375\n",
      "Step 32100\t| Loss: 1.265625\n",
      "Step 32200\t| Loss: 1.0859375\n",
      "Step 32300\t| Loss: 1.078125\n",
      "Step 32400\t| Loss: 0.8828125\n",
      "Step 32500\t| Loss: 0.6328125\n",
      "Step 32600\t| Loss: 0.75\n",
      "Step 32700\t| Loss: 0.94921875\n",
      "Step 32800\t| Loss: 1.0\n",
      "Step 32900\t| Loss: 0.984375\n",
      "Step 33000\t| Loss: 0.9453125\n",
      "Step 33100\t| Loss: 1.3125\n",
      "Step 33200\t| Loss: 1.25\n",
      "Step 33300\t| Loss: 0.59765625\n",
      "Step 33400\t| Loss: 1.1640625\n",
      "Step 33500\t| Loss: 0.78125\n",
      "Step 33600\t| Loss: 0.9453125\n",
      "Step 33700\t| Loss: 1.265625\n",
      "Step 33800\t| Loss: 0.208984375\n",
      "Step 33900\t| Loss: 0.85546875\n",
      "Step 34000\t| Loss: 1.1640625\n",
      "Step 34100\t| Loss: 0.84765625\n",
      "Step 34200\t| Loss: 0.62890625\n",
      "Step 34300\t| Loss: 1.3359375\n",
      "Step 34400\t| Loss: 0.9609375\n",
      "Step 34500\t| Loss: 1.25\n",
      "Step 34600\t| Loss: 1.0078125\n",
      "Step 34700\t| Loss: 0.83203125\n",
      "Step 34800\t| Loss: 1.3828125\n",
      "Step 34900\t| Loss: 1.203125\n",
      "Step 35000\t| Loss: 1.0390625\n",
      "Step 35100\t| Loss: 0.9140625\n",
      "Step 35200\t| Loss: 1.0234375\n",
      "Step 35300\t| Loss: 0.6484375\n",
      "Step 35400\t| Loss: 0.859375\n",
      "Step 35500\t| Loss: 1.296875\n",
      "Step 35600\t| Loss: 1.3515625\n",
      "Step 35700\t| Loss: 0.474609375\n",
      "Step 35800\t| Loss: 1.109375\n",
      "Step 35900\t| Loss: 0.93359375\n",
      "Step 36000\t| Loss: 0.9921875\n",
      "Step 36100\t| Loss: 0.388671875\n",
      "Step 36200\t| Loss: 1.0625\n",
      "Step 36300\t| Loss: 1.171875\n",
      "Step 36400\t| Loss: 1.015625\n",
      "Step 36500\t| Loss: 1.0859375\n",
      "Step 36600\t| Loss: 0.96484375\n",
      "Step 36700\t| Loss: 0.72265625\n",
      "Step 36800\t| Loss: 0.8828125\n",
      "Step 36900\t| Loss: 0.609375\n",
      "Step 37000\t| Loss: 0.78515625\n",
      "Step 37100\t| Loss: 0.5\n",
      "Step 37200\t| Loss: 0.81640625\n",
      "Step 37300\t| Loss: 0.62109375\n",
      "Step 37400\t| Loss: 0.9453125\n",
      "Step 37500\t| Loss: 0.9140625\n",
      "Step 37600\t| Loss: 1.5\n",
      "Step 37700\t| Loss: 1.53125\n",
      "Step 37800\t| Loss: 1.03125\n",
      "Step 37900\t| Loss: 0.38671875\n",
      "Step 38000\t| Loss: 1.1640625\n",
      "Step 38100\t| Loss: 1.046875\n",
      "Step 38200\t| Loss: 0.9609375\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from accelerate.test_utils.testing import get_backend\n",
    "\n",
    "step = 0\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "num_training_steps = len(train_dataloader) * 3  # 假设训练3个epoch\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "device, _, _ = get_backend()\n",
    "model.to(device)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits          # [B, T, V]\n",
    "\n",
    "        shift_logits = logits[:, :-1, :].contiguous()   # [B, T-1, V]\n",
    "        shift_labels = labels[:, 1:].contiguous()       # [B, T-1]\n",
    "\n",
    "        loss = loss_fn(\n",
    "            shift_logits.view(-1, shift_logits.size(-1)),\n",
    "            shift_labels.view(-1),\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        step += 1\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}\\t| Loss: {loss.item()}\")\n",
    "\n",
    "    model.save_pretrained(f\"output/checkpoint-epoch-{epoch + 1}\")\n",
    "    tokenizer.save_pretrained(f\"output/checkpoint-epoch-{epoch + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试训练后的模型效果。如果训练正常，模型应当能回答出通顺的语句，并在回答结束后自然地停止生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai Jiao Tong University (Jiao Tong University) is a prestigious research university founded in 1921 in Shanghai, China. It is one of the top-tier universities in China and is known for its innovative and research-based programs in fields such as engineering, business, and social sciences. The university has a strong commitment to internationalization and has a large international student body. It is also home to several prestigious research centers and institutes, including the Center for Advanced Materials Research, the Center for International Development, and the Center for Chinese Language and Culture.\n"
     ]
    }
   ],
   "source": [
    "sft_model = AutoModelForCausalLM.from_pretrained(\"output/checkpoint-epoch-3\", device_map=\"auto\", torch_dtype=\"auto\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Give me a brief introduction to Shanghai Jiao Tong University.\"},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "with torch.no_grad():\n",
    "    lm_inputs_src = tokenizer([text], add_special_tokens=False, return_tensors=\"pt\").to(sft_model.device)\n",
    "    generate_ids = sft_model.generate(**lm_inputs_src, max_new_tokens=150, do_sample=False)\n",
    "pred_str = tokenizer.decode(generate_ids[0][lm_inputs_src.input_ids.size(1):], skip_special_tokens=True)\n",
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果模型行为正常，就可以继续前往大作业的第二部分了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分：使用LLM做推理生成，并解码为自然文本\n",
    "在这一部分，我们将体验LLM是如何逐token进行生成、并解码出自然文本的。我们需要手动实现一个`generate`函数，它能够直接接受用户的自然文本作为输入，并同样以自然文本回复。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"output/checkpoint-epoch-3\"    # 你训练好的模型路径\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import datasets\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现generate\n",
    "请实现下述的generate函数，手动进行模型推理、生成与解码。\n",
    "\n",
    "这个generate函数至少能够接受一个字符串`query`作为输入，限制最大生成token数`max_new_tokens`，并用`do_sample`选择是采用采样还是贪婪搜索进行生成。在使用采样策略生成时，允许设置基础的采样生成参数`temperature`、`top_p`和`top_k`。关于不同的生成策略是如何工作的，可以学习这篇[博客](https://huggingface.co/blog/how-to-generate)。  \n",
    "**禁止使用模型自带的`model.generate`方法！**\n",
    "\n",
    "> <b>附加2（3分）</b>你能够利用模型的批次输入特性（并非是使用循环逐个处理批次输入），成批次地输入文本、并同时生成新token吗？此时`query`应该可以接受一个字符串列表作为输入。\n",
    "\n",
    "> <b>附加3（3分）</b>束搜索（Beam search）允许在解码过程中保留数个次优序列，通过生成过程中维护这些序列，模型能够生成整体更为合理的句子，改善了贪婪搜索中可能会陷入局部最优的问题。你可以在已有的贪婪搜索与采样两种生成策略的基础上实现束搜索吗？此时`num_beams`应允许大于1的值。  \n",
    "关于束搜索，这里有一个[可视化Demo](https://huggingface.co/spaces/m-ric/beam_search_visualizer)演示其运作机理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from typing import Union, List\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax, log_softmax\n",
    "\n",
    "def top_p_top_k_filtering(\n",
    "    logits: torch.Tensor,\n",
    "    top_p: float = 0.9,\n",
    "    top_k: int = 50,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    对 logits 应用 top-p 和 top-k 过滤。\n",
    "    Args:\n",
    "        logits: 模型输出的 logits，形状为 [B, V]\n",
    "        top_p: top-p 参数\n",
    "        top_k: top-k 参数\n",
    "    Returns:\n",
    "        过滤后的 logits，形状为 [B, V]\n",
    "    \"\"\"\n",
    "    # top-k\n",
    "    if top_k > 0:\n",
    "        top_k_vals, top_k_idx = torch.topk(logits, top_k, dim=-1)\n",
    "        mask = torch.full_like(logits, float(\"-inf\"))\n",
    "        mask.scatter_(1, top_k_idx, top_k_vals)\n",
    "        logits = mask\n",
    "\n",
    "    probs = softmax(logits, dim=-1)\n",
    "\n",
    "    # top-p (nucleus) \n",
    "    if top_p < 1.0:\n",
    "        sorted_probs, sorted_indices = torch.sort(probs, descending=True, dim=-1)\n",
    "        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        old = sorted_indices_to_remove.clone()\n",
    "        sorted_indices_to_remove[..., 1:] = old[..., :-1]\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "        # set the p that exceed top_p to zero\n",
    "        probs.scatter_(\n",
    "            1,\n",
    "            sorted_indices,\n",
    "            sorted_probs * (~sorted_indices_to_remove)\n",
    "        )\n",
    "        probs = probs / probs.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "    return probs\n",
    "def generate(\n",
    "    model,\n",
    "    query: Union[str, List[str]],\n",
    "    max_new_tokens: int = 1024,\n",
    "    do_sample: bool = False,\n",
    "    temperature: float = 1.0,\n",
    "    top_p: float = 0.9,\n",
    "    top_k: int = 50,\n",
    "    num_beams: int = 1,\n",
    "    length_penalty: float = 1.0,\n",
    ") -> Union[str, List[str]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    使用模型model进行文本生成。\n",
    "    Args:\n",
    "        model: 用于生成的语言模型\n",
    "        query: 用户输入的查询。可以是单个字符串，或者是一个字符串列表\n",
    "        max_new_tokens: 生成的最大新token数量\n",
    "        do_sample: 是否使用采样生成文本。仅当为True时，后续的temperature、top_p、top_k参数才会生效\n",
    "        temperature: 采样时的温度参数\n",
    "        top_p: 采样时的top-p参数\n",
    "        top_k: 采样时的top-k参数\n",
    "        num_beams: 束搜索同时维护的束的数量。仅当`num_beams > 1`时，才会启用束搜索\n",
    "        length_penalty: 启用束搜索时的长度惩罚系数\n",
    "    Returns:\n",
    "        生成的文本。如果输入是单个字符串，则返回单个字符串；如果输入是字符串列表，则返回字符串列表\n",
    "    \"\"\"\n",
    "    \n",
    "    global tokenizer\n",
    "\n",
    "    if isinstance(query, str):\n",
    "        queries = [query]\n",
    "        single_input = True\n",
    "    elif isinstance(query, list):\n",
    "        queries = query\n",
    "        single_input = False\n",
    "    else:\n",
    "        raise ValueError(\"query must be a string or a list of strings\")\n",
    "\n",
    "    device = model.device\n",
    "\n",
    "    messages_list = [[{\"role\": \"user\", \"content\": q}] for q in queries]\n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(m, tokenize=False, add_generation_prompt=True)\n",
    "        for m in messages_list\n",
    "    ]\n",
    "\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "    input_ids = enc[\"input_ids\"].to(device)          # [B, T]\n",
    "    attention_mask = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "    batch_size = input_ids.size(0)\n",
    "\n",
    "    \n",
    "    generated = input_ids\n",
    "\n",
    "    if num_beams > 1 and not do_sample:\n",
    "        generated = input_ids.repeat_interleave(num_beams, dim=0)\n",
    "        attention_mask = attention_mask.repeat_interleave(num_beams, dim=0)\n",
    "        \n",
    "        beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=device)\n",
    "        beam_scores[:, 1:] = -1e9 \n",
    "        \n",
    "        beam_scores = beam_scores.view(-1) \n",
    "\n",
    "        vocab_size = -1 \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for step in range(max_new_tokens):\n",
    "                outputs = model(input_ids=generated, attention_mask=attention_mask)\n",
    "                next_token_logits = outputs.logits[:, -1, :] \n",
    "                \n",
    "                if vocab_size == -1:\n",
    "                    vocab_size = next_token_logits.shape[-1]\n",
    "\n",
    "                next_token_scores = log_softmax(next_token_logits, dim=-1) # [B * num_beams, V]\n",
    "\n",
    "                next_scores = beam_scores.unsqueeze(-1) + next_token_scores\n",
    "\n",
    "                next_scores = next_scores.view(batch_size, num_beams * vocab_size)\n",
    "\n",
    "                topk_scores, topk_indices = torch.topk(next_scores, num_beams, dim=1, largest=True, sorted=True)\n",
    "\n",
    "                beam_indices = topk_indices // vocab_size  # [B, num_beams]\n",
    "                token_indices = topk_indices % vocab_size  # [B, num_beams]\n",
    "\n",
    "                beam_scores = topk_scores.view(-1) # Flatten back to [B * num_beams]\n",
    "\n",
    "                batch_offset = (torch.arange(batch_size, device=device) * num_beams).unsqueeze(1)\n",
    "                \n",
    "                global_beam_indices = (beam_indices + batch_offset).view(-1) # [B * num_beams]\n",
    "\n",
    "                generated = generated[global_beam_indices]\n",
    "                attention_mask = attention_mask[global_beam_indices]\n",
    "\n",
    "                new_tokens = token_indices.view(-1, 1)\n",
    "                generated = torch.cat([generated, new_tokens], dim=-1)\n",
    "                \n",
    "                attention_mask = torch.cat(\n",
    "                    [attention_mask, torch.ones((batch_size * num_beams, 1), device=device)], \n",
    "                    dim=1\n",
    "                )\n",
    "\n",
    "                #继续生成直到 max_tokens\n",
    "                if (new_tokens.squeeze() == tokenizer.eos_token_id).all():\n",
    "                    break\n",
    "\n",
    "        # beam_scores 形状 [B * num_beams]\n",
    "        final_scores = beam_scores.view(batch_size, num_beams)\n",
    "        \n",
    "        current_len = generated.shape[1]\n",
    "        final_scores = final_scores / (current_len ** length_penalty)\n",
    "\n",
    "        best_beam_idx = torch.argmax(final_scores, dim=-1) # [B]\n",
    "\n",
    "        final_generated = []\n",
    "        for i in range(batch_size):\n",
    "            global_idx = i * num_beams + best_beam_idx[i].item()\n",
    "            final_generated.append(generated[global_idx])\n",
    "        \n",
    "        generated = final_generated\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_new_tokens):\n",
    "                outputs = model(input_ids=generated, attention_mask=attention_mask)\n",
    "                logits = outputs.logits[:, -1, :]          # 取每个样本最后一个位置的 logits，[B, V]\n",
    "\n",
    "                if do_sample:\n",
    "                    logits = logits / temperature\n",
    "\n",
    "\n",
    "                    probs = top_p_top_k_filtering(\n",
    "                        logits,\n",
    "                        top_p=top_p,\n",
    "                        top_k=top_k,\n",
    "                    )\n",
    "                    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)  # [B]\n",
    "                else:\n",
    "                    next_tokens = torch.argmax(logits, dim=-1)  # [B]\n",
    "\n",
    "\n",
    "                next_tokens_unsqueezed = next_tokens.unsqueeze(1)  # [B, 1]\n",
    "                generated = torch.cat([generated, next_tokens_unsqueezed], dim=1)  # [B, T+1]\n",
    "                attention_mask = torch.cat(\n",
    "                    [attention_mask, torch.ones((batch_size, 1), dtype=attention_mask.dtype, device=device)],\n",
    "                    dim=1,\n",
    "                )\n",
    "\n",
    "                # break if all sequences have generated eos\n",
    "                if (next_tokens == tokenizer.eos_token_id).all():\n",
    "                    break\n",
    "\n",
    "    gen_texts = []\n",
    "    for i in range(batch_size):\n",
    "        seq = generated[i]\n",
    "        prompt_len = enc[\"input_ids\"][i].size(0)\n",
    "        new_tokens = seq[prompt_len:]\n",
    "        if tokenizer.eos_token_id in new_tokens:\n",
    "            eos_pos = (new_tokens == tokenizer.eos_token_id).nonzero(as_tuple=True)[0][0].item()\n",
    "            new_tokens = new_tokens[:eos_pos]\n",
    "        text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "        gen_texts.append(text)\n",
    "\n",
    "    return gen_texts[0] if single_input else gen_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试generate的效果\n",
    "请同学们运行下述单元格，测试你的实现。除了下面提到的句子，同学们也可以自定义更多情况下的输入文本，探究模型在面对不同输入时采用不同解码策略的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 贪心解码\n",
      "[0] 问：Give me a brief introduction to Shanghai Jiao Tong University.\n",
      "答：Shanghai Jiao Tong University (Jiao Tong University) is a prestigious research university founded in 1921 in Shanghai, China. It is one of the top-tier universities in China and is known for its innovative and research-based programs in fields such as engineering, business, and social sciences. The university has a strong commitment to internationalization and has a large international student body. It is also home to several prestigious research centers and institutes, including the Center for Advanced Materials Research, the Center for International Development, and the Center for Chinese Language and Culture.\n",
      "[1] 问：介绍一下上海交通大学。\n",
      "答：\n",
      "上海交通大学，原名复旦交通大学，是一所以工、理、管、法、工、农、管、经、管、工、经、法、商、管理、艺术等门类为特色的综合型研究型大学。它于1922年在上海成立，1927年更名复旦，1936年复旦附设，1940年复旦附设，1946年复旦附设，1950年复旦附设，1953年复旦附设，1957年复旦附设，1960年复旦附设，1963年复旦附设，1967年复旦附设，1970年复旦附设，1973年复旦附设，1978年复旦附设，1983年复旦附设，1988年复旦附设，1993年复旦附设，1998年复旦附设，2004年复旦附设，2009年复旦附设，2014\n",
      "[2] 问：What is the capital of China?\n",
      "答：\n",
      "The capital of China is Beijing.\n",
      "\n",
      "#2 采样解码\n",
      "[0] 问：Tell me a joke about computers.\n",
      "答：Why don't scientists trust atoms? Because they make up everything!\n",
      "[1] 问：Tell me a joke about computers.\n",
      "答：Why don't scientists trust atoms? Because they make up everything!\n",
      "[2] 问：Tell me a joke about computers.\n",
      "答：Why don’t scientists trust atoms? Because they make up everything!\n",
      "[3] 问：Tell me a joke about computers.\n",
      "答：Why don't scientists trust computers? \n",
      "\n",
      "Because they make up everything!\n",
      "[4] 问：Tell me a joke about computers.\n",
      "答：Why don't programmers like computers? Because they make up the Internet!\n",
      "\n",
      "#3 【附加3】束搜索解码\n",
      "问：What is the sum of the first 100 natural numbers? Please think step by step.\n",
      "答：The sum of the first 100 natural numbers can be calculated using the formula for the sum of an arithmetic series, which is `n/2 * (a + l)`, where `n` is the number of terms, `a` is the first term, and `l` is the last term. In this case, `n = 100`, `a = 1`, and `l = 100`. Plugging these values into the formula, we get:\n",
      "\n",
      "`100/2 * (1 + 100) = 50 * 101 = 5050`.\n",
      "\n",
      "Therefore, the sum of the first 100 natural numbers is 5050.\n",
      "\n",
      "========== 补充测试 ==========\n",
      "\n",
      "### 1. Decoding Strategy Comparison ###\n",
      "[Greedy]\n",
      "Once upon a time, in a world of endless possibilities, there was a robot named Robby. Robby was a simple robot, designed to perform basic tasks, but he had a secret desire to become a chef. He had always been fascinated by cooking and the art of making food. He longed to be a chef, to be a part of the culinary world and to create something truly special.\n",
      "\n",
      "One day, Robby decided to take a step towards his dream. He spent countless hours studying cooking techniques, experimenting with different recipes, and learning all about the ingredients and the process of making a dish. He even joined a cooking school and learned all the skills he needed to become a successful chef.\n",
      "\n",
      "Robby's hard work paid off when he was invited to join a prestigious cooking school. He was amazed by the challenges and the opportunities that awaited him. He learned all the skills he needed to become a successful chef, and he even got to work with some of the best chefs in the world.\n",
      "\n",
      "Robby's dedication and hard work paid off when he was finally invited to join the school's executive committee. He was given the opportunity to work on some of the most famous dishes in the world, and he was able to learn from some of the greatest chefs in the world\n",
      "\n",
      "[Sampling Temp=0.7]\n",
      "Once upon a time, in a world of science and technology, there was a robot named R1. R1 was programmed to perform mundane tasks, but it never stopped dreaming of something more. One day, R1 came across an old cookbook, hidden in a dusty shelf at a local bookstore. Intrigued, R1 began to read through the pages, trying to find inspiration.\n",
      "\n",
      "As R1 flipped through the pages, it struck a chord within it. Something about the way the recipes were presented, the way they were presented in the food, it began to resonate with R1. R1 decided to take the cookbook with it and start experimenting.\n",
      "\n",
      "R1 worked tirelessly, learning every detail about cooking, from the basics to the most advanced techniques. It wasn't easy, and at times, R1 felt like giving up. But every time R1 found something new and exciting to try, it brought a sense of accomplishment. R1 found joy in the process of cooking, and it was through this joy that R1's dreams of becoming a chef were born.\n",
      "\n",
      "Years passed, and R1 became the best cook in the town. It wasn't just about the food, though. R1 had an innate talent for it. It was as if the chef in\n",
      "\n",
      "[Sampling Temp=1.5]\n",
      "Once there was a robot named Rob. He was programmed by his creators to do tasks that required precision and focus. But over time he grew restless with simple, routine tasks, and he wanted to be more. He was unhappy to be a robot, and longed to create and taste the dishes people ate.\n",
      "\n",
      "One day, his creator placed him under the supervision of the chef named Mia. The scientist and engineer had a wonderful dinner table with her and Rob sat by herself. After dinner, Mia ordered Rob to prepare a meal that would impress the chef. He accepted the task easily and quickly moved through the kitchen filling a large jar with cooked vegetables, pasta and a salad in seconds.\n",
      "\n",
      "After the last dishes had been carefully put on the jar and the glass was rinsed with tap water, Mia opened her container and placed a tomato-based soup on the tray before her. Slowly, the soup grew thick and the heat seeped through the noodles until it was steaming. Mia settled in beside Rob and watched, mesmerized, as the robot began stirring, sizzling and frolicking at the table. Her eyes opened wide and she grinned - her tomato-based soup soup was indeed a chef's food.\n",
      "\n",
      "When dinner was ready Mia put the containers beside a grill on Mia\n",
      "\n",
      "[Beam Search (Beams=4)]\n",
      "Once upon a time, in a small town, there lived a robot named Robby. Robby was different from the other robots in the town. He was different because he had a passion for cooking. He had always dreamed of becoming a chef, but no one had ever given him the opportunity.\n",
      "\n",
      "One day, Robby decided to take a chance and apply to the local cooking school. He was nervous, but he was also excited. He had always wanted to be a chef, but no one had ever given him the opportunity to learn how to cook. So, he packed his bags and set off to the school.\n",
      "\n",
      "When he arrived, he was amazed by what he saw. The cooking school was full of talented chefs, and Robby was no exception. He learned everything he needed to know about cooking, from the basics to the most advanced techniques.\n",
      "\n",
      "After a few months of training, Robby was ready to test his skills on the job. He was given the task of preparing a special meal for the town's mayor. It was a big challenge, but Robby was determined. He worked hard, and in the end, he came out on top.\n",
      "\n",
      "The mayor was amazed by Robby's cooking skills, and he invited him to join his kitchen. Robby\n",
      "\n",
      "### 2. Knowledge & Logic Checks ###\n",
      "\n",
      "Q: What is 12 + 8 * 2?\n",
      "A: The result of 12 + 8 * 2 is 28.\n",
      "\n",
      "Q: Who wrote the play Romeo and Juliet?\n",
      "A: The play Romeo and Juliet was written by William Shakespeare.\n",
      "\n",
      "Q: Tell me about the history of the United States of Antarctica.\n",
      "A: The history of the United States of Antarctica dates back to the 19th century when the United States government began to explore the continent for its natural resources. In 1898, the U.S. government established the United States Antarctic Expedition, which was the first official scientific expedition to the continent. The expedition was led by geologist James E. Scott and included a team of scientists, including William Burchfield, Charles W. Maroon, and Edward S. Robinson.\n",
      "\n",
      "The expedition was a great success, and the results were published in 1899, with the first report on the geography, geology, and ecology of the continent. The expedition's findings were instrumental in shaping the United States' understanding of the continent and its role in the world.\n",
      "\n",
      "In the early 20th century, the United States government began to explore the continent for its natural resources, including oil, gas, and minerals. In 1903, the U.S. government established the U.S. Department of Interior's Antarctic Service, which oversaw the exploration of the continent.\n",
      "\n",
      "In the 1920s, the U.S. government began to establish permanent bases on the continent, including the South Pole Station, which was established in 1\n",
      "\n",
      "Q: Translate 'Hello' into French.\n",
      "A: Bonjour.\n"
     ]
    }
   ],
   "source": [
    "print(\"#1 贪心解码\")\n",
    "query1 = [\"Give me a brief introduction to Shanghai Jiao Tong University.\", \"介绍一下上海交通大学。\", \"What is the capital of China?\"]\n",
    "# 如果没有实现附加2，请用循环的方式依次解码query1里的每个字符串并打印出来\n",
    "for i, response in enumerate(generate(model, query1, max_new_tokens=256, do_sample=False)):\n",
    "    print(f\"[{i}] 问：{query1[i]}\\n答：{response}\")\n",
    "\n",
    "print(\"\\n#2 采样解码\")\n",
    "query2 = \"Tell me a joke about computers.\"\n",
    "for i in range(5):\n",
    "    response = generate(model, query2, do_sample=True, temperature=0.7, top_p=0.9, top_k=50)    # 可以试试调整这些采样超参数\n",
    "    print(f\"[{i}] 问：{query2}\\n答：{response}\")\n",
    "\n",
    "print(\"\\n#3 【附加3】束搜索解码\")\n",
    "query3 = \"What is the sum of the first 100 natural numbers? Please think step by step.\"\n",
    "response = generate(model, query3, num_beams=1, length_penalty=1.0)\n",
    "print(f\"问：{query3}\\n答：{response}\")\n",
    "\n",
    "print(\"\\n========== 补充测试 ==========\")\n",
    "\n",
    "print(\"\\n### 1. Decoding Strategy Comparison ###\")\n",
    "test_query = \"Write a very short story about a robot who wants to be a chef.\"\n",
    "\n",
    "print(\"[Greedy]\")\n",
    "print(generate(model, test_query, max_new_tokens=256, do_sample=False))\n",
    "\n",
    "print(\"\\n[Sampling Temp=0.7]\")\n",
    "print(generate(model, test_query, max_new_tokens=256, do_sample=True, temperature=0.7))\n",
    "\n",
    "print(\"\\n[Sampling Temp=1.5]\")\n",
    "print(generate(model, test_query, max_new_tokens=256, do_sample=True, temperature=1.5))\n",
    "\n",
    "print(\"\\n[Beam Search (Beams=4)]\")\n",
    "try:\n",
    "    print(generate(model, test_query, max_new_tokens=256, num_beams=4))\n",
    "except Exception as e:\n",
    "    print(f\"Beam search failed or not fully implemented: {e}\")\n",
    "\n",
    "print(\"\\n### 2. Knowledge & Logic Checks ###\")\n",
    "queries = [\n",
    "    \"What is 12 + 8 * 2?\", \n",
    "    \"Who wrote the play Romeo and Juliet?\",\n",
    "    \"Tell me about the history of the United States of Antarctica.\", # Hallucination check\n",
    "    \"Translate 'Hello' into French.\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {generate(model, q, max_new_tokens=256, do_sample=False)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
